{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\648473009.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_csv_files(base_directory, folder_name, file_patterns):\n",
    "    \"\"\"\n",
    "    Combines CSV files from a specified folder within the base directory into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - base_directory (str): The base directory where the subfolder is located.\n",
    "    - folder_name (str): The name of the subfolder containing CSV files.\n",
    "    - file_patterns (list of str): List of file name patterns to match.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing the combined data from all CSV files that match the specified patterns.\n",
    "    \"\"\"\n",
    "    # Construct the full directory path\n",
    "    directory_path = os.path.join(base_directory, folder_name)\n",
    "\n",
    "    # Use glob to get a list of file paths that match the patterns\n",
    "    files = []\n",
    "    for pattern in file_patterns:\n",
    "        files.extend(glob.glob(os.path.join(directory_path, pattern)))\n",
    "\n",
    "    # Initialize an empty DataFrame to store the combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through the list of file paths\n",
    "    for file in files:\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Append the data from the current file to the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_9508\\2889006002.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Example usage with multiple patterns\n",
    "import os\n",
    "\n",
    "base_directory = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_folder = os.path.join(base_directory, 'data')\n",
    "validation_folder = os.path.join(data_folder, 'validation')\n",
    "test_folder = os.path.join(data_folder, 'test')\n",
    "training_folder = os.path.join(data_folder, 'training')\n",
    "\n",
    "# base_directory = 'data'\n",
    "# folder_to_combine = '\\validation'\n",
    "file_patterns = ['CMP-validation-*.csv', 'CMP-training-*.csv', 'CMP-test-*.csv']\n",
    "validation = combine_csv_files(data_folder, validation_folder, file_patterns)\n",
    "test = combine_csv_files(data_folder, test_folder, file_patterns)\n",
    "training = combine_csv_files(data_folder, training_folder, file_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACHINE_ID</th>\n",
       "      <th>MACHINE_DATA</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>WAFER_ID</th>\n",
       "      <th>STAGE</th>\n",
       "      <th>CHAMBER</th>\n",
       "      <th>USAGE_OF_BACKING_FILM</th>\n",
       "      <th>USAGE_OF_DRESSER</th>\n",
       "      <th>USAGE_OF_POLISHING_TABLE</th>\n",
       "      <th>USAGE_OF_DRESSER_TABLE</th>\n",
       "      <th>...</th>\n",
       "      <th>USAGE_OF_PRESSURIZED_SHEET</th>\n",
       "      <th>SLURRY_FLOW_LINE_A</th>\n",
       "      <th>SLURRY_FLOW_LINE_B</th>\n",
       "      <th>SLURRY_FLOW_LINE_C</th>\n",
       "      <th>WAFER_ROTATION</th>\n",
       "      <th>STAGE_ROTATION</th>\n",
       "      <th>HEAD_ROTATION</th>\n",
       "      <th>DRESSING_WATER_STATUS</th>\n",
       "      <th>EDGE_AIR_BAG_PRESSURE</th>\n",
       "      <th>AVG_REMOVAL_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.816382e+08</td>\n",
       "      <td>-2697400572</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9333.333333</td>\n",
       "      <td>535.185185</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.816382e+08</td>\n",
       "      <td>-2697400572</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9333.333333</td>\n",
       "      <td>535.185185</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.816382e+08</td>\n",
       "      <td>-2697400572</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9333.333333</td>\n",
       "      <td>535.185185</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>72.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.816382e+08</td>\n",
       "      <td>-2697400572</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9333.333333</td>\n",
       "      <td>535.185185</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>14.027778</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>235.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.816382e+08</td>\n",
       "      <td>-2697400572</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9333.333333</td>\n",
       "      <td>535.185185</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>17.083333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>305.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MACHINE_ID MACHINE_DATA     TIMESTAMP     WAFER_ID STAGE  CHAMBER  \\\n",
       "0          2            4  4.816382e+08  -2697400572     B      4.0   \n",
       "1          2            4  4.816382e+08  -2697400572     B      4.0   \n",
       "2          2            4  4.816382e+08  -2697400572     B      4.0   \n",
       "3          2            4  4.816382e+08  -2697400572     B      4.0   \n",
       "4          2            4  4.816382e+08  -2697400572     B      4.0   \n",
       "\n",
       "   USAGE_OF_BACKING_FILM  USAGE_OF_DRESSER  USAGE_OF_POLISHING_TABLE  \\\n",
       "0            9333.333333        535.185185                     320.0   \n",
       "1            9333.333333        535.185185                     320.0   \n",
       "2            9333.333333        535.185185                     320.0   \n",
       "3            9333.333333        535.185185                     320.0   \n",
       "4            9333.333333        535.185185                     320.0   \n",
       "\n",
       "   USAGE_OF_DRESSER_TABLE  ...  USAGE_OF_PRESSURIZED_SHEET  \\\n",
       "0                  2667.0  ...                      2800.0   \n",
       "1                  2667.0  ...                      2800.0   \n",
       "2                  2667.0  ...                      2800.0   \n",
       "3                  2667.0  ...                      2800.0   \n",
       "4                  2667.0  ...                      2800.0   \n",
       "\n",
       "   SLURRY_FLOW_LINE_A  SLURRY_FLOW_LINE_B  SLURRY_FLOW_LINE_C  WAFER_ROTATION  \\\n",
       "0            2.222222            0.909091                 0.0             0.0   \n",
       "1            2.222222            0.909091                 0.0             0.0   \n",
       "2            3.888889            0.909091                72.8             0.0   \n",
       "3           14.027778            0.909091               235.2             0.0   \n",
       "4           17.083333            0.909091               305.2             0.0   \n",
       "\n",
       "   STAGE_ROTATION  HEAD_ROTATION  DRESSING_WATER_STATUS  \\\n",
       "0             0.0          160.0                    1.0   \n",
       "1             0.0          160.0                    1.0   \n",
       "2             0.0          160.0                    1.0   \n",
       "3             0.0          160.0                    1.0   \n",
       "4             0.0          156.8                    1.0   \n",
       "\n",
       "   EDGE_AIR_BAG_PRESSURE  AVG_REMOVAL_RATE  \n",
       "0                    0.0               NaN  \n",
       "1                    0.0               NaN  \n",
       "2                    0.0               NaN  \n",
       "3                    0.0               NaN  \n",
       "4                    0.0               NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144572, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(674725, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156686, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MACHINE_ID                       object\n",
       "MACHINE_DATA                     object\n",
       "TIMESTAMP                       float64\n",
       "WAFER_ID                         object\n",
       "STAGE                            object\n",
       "CHAMBER                         float64\n",
       "USAGE_OF_BACKING_FILM           float64\n",
       "USAGE_OF_DRESSER                float64\n",
       "USAGE_OF_POLISHING_TABLE        float64\n",
       "USAGE_OF_DRESSER_TABLE          float64\n",
       "PRESSURIZED_CHAMBER_PRESSURE    float64\n",
       "MAIN_OUTER_AIR_BAG_PRESSURE     float64\n",
       "CENTER_AIR_BAG_PRESSURE         float64\n",
       "RETAINER_RING_PRESSURE          float64\n",
       "RIPPLE_AIR_BAG_PRESSURE         float64\n",
       "USAGE_OF_MEMBRANE               float64\n",
       "USAGE_OF_PRESSURIZED_SHEET      float64\n",
       "SLURRY_FLOW_LINE_A              float64\n",
       "SLURRY_FLOW_LINE_B              float64\n",
       "SLURRY_FLOW_LINE_C              float64\n",
       "WAFER_ROTATION                  float64\n",
       "STAGE_ROTATION                  float64\n",
       "HEAD_ROTATION                   float64\n",
       "DRESSING_WATER_STATUS           float64\n",
       "EDGE_AIR_BAG_PRESSURE           float64\n",
       "AVG_REMOVAL_RATE                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>CHAMBER</th>\n",
       "      <th>USAGE_OF_BACKING_FILM</th>\n",
       "      <th>USAGE_OF_DRESSER</th>\n",
       "      <th>USAGE_OF_POLISHING_TABLE</th>\n",
       "      <th>USAGE_OF_DRESSER_TABLE</th>\n",
       "      <th>PRESSURIZED_CHAMBER_PRESSURE</th>\n",
       "      <th>MAIN_OUTER_AIR_BAG_PRESSURE</th>\n",
       "      <th>CENTER_AIR_BAG_PRESSURE</th>\n",
       "      <th>RETAINER_RING_PRESSURE</th>\n",
       "      <th>...</th>\n",
       "      <th>USAGE_OF_PRESSURIZED_SHEET</th>\n",
       "      <th>SLURRY_FLOW_LINE_A</th>\n",
       "      <th>SLURRY_FLOW_LINE_B</th>\n",
       "      <th>SLURRY_FLOW_LINE_C</th>\n",
       "      <th>WAFER_ROTATION</th>\n",
       "      <th>STAGE_ROTATION</th>\n",
       "      <th>HEAD_ROTATION</th>\n",
       "      <th>DRESSING_WATER_STATUS</th>\n",
       "      <th>EDGE_AIR_BAG_PRESSURE</th>\n",
       "      <th>AVG_REMOVAL_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.727440e+05</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>672744.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.844186e+08</td>\n",
       "      <td>4.223673</td>\n",
       "      <td>4968.532485</td>\n",
       "      <td>396.444964</td>\n",
       "      <td>171.983843</td>\n",
       "      <td>3496.348712</td>\n",
       "      <td>49.973427</td>\n",
       "      <td>155.327976</td>\n",
       "      <td>40.147023</td>\n",
       "      <td>1218.777316</td>\n",
       "      <td>...</td>\n",
       "      <td>1490.559854</td>\n",
       "      <td>4.245952</td>\n",
       "      <td>0.725417</td>\n",
       "      <td>249.354458</td>\n",
       "      <td>12.802433</td>\n",
       "      <td>52.437560</td>\n",
       "      <td>159.792734</td>\n",
       "      <td>0.424763</td>\n",
       "      <td>28.531700</td>\n",
       "      <td>98.631645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.639134e+06</td>\n",
       "      <td>1.333534</td>\n",
       "      <td>2888.628864</td>\n",
       "      <td>219.524524</td>\n",
       "      <td>94.623563</td>\n",
       "      <td>479.742809</td>\n",
       "      <td>39.241073</td>\n",
       "      <td>133.191797</td>\n",
       "      <td>34.240954</td>\n",
       "      <td>1499.216737</td>\n",
       "      <td>...</td>\n",
       "      <td>866.588654</td>\n",
       "      <td>6.683546</td>\n",
       "      <td>0.420575</td>\n",
       "      <td>214.034647</td>\n",
       "      <td>16.325427</td>\n",
       "      <td>91.878220</td>\n",
       "      <td>8.889108</td>\n",
       "      <td>0.494307</td>\n",
       "      <td>24.346485</td>\n",
       "      <td>187.429160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.816344e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>5.185185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2664.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.426550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.827736e+08</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2425.000000</td>\n",
       "      <td>205.185185</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>3041.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>727.500000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.846534e+08</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5036.666667</td>\n",
       "      <td>395.925926</td>\n",
       "      <td>172.592593</td>\n",
       "      <td>3544.750000</td>\n",
       "      <td>72.857143</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>1446.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>1511.000000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>411.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.939394</td>\n",
       "      <td>79.154850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.857991e+08</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7322.500000</td>\n",
       "      <td>590.370370</td>\n",
       "      <td>254.074074</td>\n",
       "      <td>3912.000000</td>\n",
       "      <td>77.142857</td>\n",
       "      <td>268.800000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>1454.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>2196.750000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>439.600000</td>\n",
       "      <td>34.651163</td>\n",
       "      <td>65.526316</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.484848</td>\n",
       "      <td>88.702050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.872682e+08</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10532.500000</td>\n",
       "      <td>771.851852</td>\n",
       "      <td>357.037037</td>\n",
       "      <td>4305.500000</td>\n",
       "      <td>189.047619</td>\n",
       "      <td>499.200000</td>\n",
       "      <td>139.375000</td>\n",
       "      <td>10662.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>3159.750000</td>\n",
       "      <td>42.638889</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1083.600000</td>\n",
       "      <td>34.883721</td>\n",
       "      <td>263.552632</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>141.515152</td>\n",
       "      <td>4326.154050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TIMESTAMP        CHAMBER  USAGE_OF_BACKING_FILM  USAGE_OF_DRESSER  \\\n",
       "count  6.727440e+05  672744.000000          672744.000000     672744.000000   \n",
       "mean   4.844186e+08       4.223673            4968.532485        396.444964   \n",
       "std    1.639134e+06       1.333534            2888.628864        219.524524   \n",
       "min    4.816344e+08       1.000000              19.166667          5.185185   \n",
       "25%    4.827736e+08       4.000000            2425.000000        205.185185   \n",
       "50%    4.846534e+08       4.000000            5036.666667        395.925926   \n",
       "75%    4.857991e+08       5.000000            7322.500000        590.370370   \n",
       "max    4.872682e+08       6.000000           10532.500000        771.851852   \n",
       "\n",
       "       USAGE_OF_POLISHING_TABLE  USAGE_OF_DRESSER_TABLE  \\\n",
       "count             672744.000000           672744.000000   \n",
       "mean                 171.983843             3496.348712   \n",
       "std                   94.623563              479.742809   \n",
       "min                    0.000000             2664.750000   \n",
       "25%                   88.888889             3041.000000   \n",
       "50%                  172.592593             3544.750000   \n",
       "75%                  254.074074             3912.000000   \n",
       "max                  357.037037             4305.500000   \n",
       "\n",
       "       PRESSURIZED_CHAMBER_PRESSURE  MAIN_OUTER_AIR_BAG_PRESSURE  \\\n",
       "count                 672744.000000                672744.000000   \n",
       "mean                      49.973427                   155.327976   \n",
       "std                       39.241073                   133.191797   \n",
       "min                        0.000000                     0.000000   \n",
       "25%                        0.000000                     0.000000   \n",
       "50%                       72.857143                   252.000000   \n",
       "75%                       77.142857                   268.800000   \n",
       "max                      189.047619                   499.200000   \n",
       "\n",
       "       CENTER_AIR_BAG_PRESSURE  RETAINER_RING_PRESSURE  ...  \\\n",
       "count            672744.000000           672744.000000  ...   \n",
       "mean                 40.147023             1218.777316  ...   \n",
       "std                  34.240954             1499.216737  ...   \n",
       "min                   0.000000                0.000000  ...   \n",
       "25%                   0.000000                0.000000  ...   \n",
       "50%                  61.250000             1446.900000  ...   \n",
       "75%                  66.250000             1454.700000  ...   \n",
       "max                 139.375000            10662.600000  ...   \n",
       "\n",
       "       USAGE_OF_PRESSURIZED_SHEET  SLURRY_FLOW_LINE_A  SLURRY_FLOW_LINE_B  \\\n",
       "count               672744.000000       672744.000000       672744.000000   \n",
       "mean                  1490.559854            4.245952            0.725417   \n",
       "std                    866.588654            6.683546            0.420575   \n",
       "min                      5.750000            0.000000            0.000000   \n",
       "25%                    727.500000            2.222222            0.909091   \n",
       "50%                   1511.000000            2.222222            0.909091   \n",
       "75%                   2196.750000            2.222222            0.909091   \n",
       "max                   3159.750000           42.638889           12.500000   \n",
       "\n",
       "       SLURRY_FLOW_LINE_C  WAFER_ROTATION  STAGE_ROTATION  HEAD_ROTATION  \\\n",
       "count       672744.000000   672744.000000   672744.000000  672744.000000   \n",
       "mean           249.354458       12.802433       52.437560     159.792734   \n",
       "std            214.034647       16.325427       91.878220       8.889108   \n",
       "min              0.000000        0.000000        0.000000       0.000000   \n",
       "25%              0.000000        0.000000        0.000000     156.800000   \n",
       "50%            411.600000        0.000000        0.000000     160.000000   \n",
       "75%            439.600000       34.651163       65.526316     160.000000   \n",
       "max           1083.600000       34.883721      263.552632     192.000000   \n",
       "\n",
       "       DRESSING_WATER_STATUS  EDGE_AIR_BAG_PRESSURE  AVG_REMOVAL_RATE  \n",
       "count          672744.000000          672744.000000       1981.000000  \n",
       "mean                0.424763              28.531700         98.631645  \n",
       "std                 0.494307              24.346485        187.429160  \n",
       "min                 0.000000               0.000000         53.426550  \n",
       "25%                 0.000000               0.000000         72.376500  \n",
       "50%                 0.000000              43.939394         79.154850  \n",
       "75%                 1.000000              48.484848         88.702050  \n",
       "max                 1.000000             141.515152       4326.154050  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_wafers = training[\"WAFER_ID\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wafer = unique_wafers[0]\n",
    "wafer_data = training[training[\"WAFER_ID\"]==wafer]\n",
    "wafer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACHINE_ID</th>\n",
       "      <th>MACHINE_DATA</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>WAFER_ID</th>\n",
       "      <th>STAGE</th>\n",
       "      <th>CHAMBER</th>\n",
       "      <th>USAGE_OF_BACKING_FILM</th>\n",
       "      <th>USAGE_OF_DRESSER</th>\n",
       "      <th>USAGE_OF_POLISHING_TABLE</th>\n",
       "      <th>USAGE_OF_DRESSER_TABLE</th>\n",
       "      <th>...</th>\n",
       "      <th>USAGE_OF_PRESSURIZED_SHEET</th>\n",
       "      <th>SLURRY_FLOW_LINE_A</th>\n",
       "      <th>SLURRY_FLOW_LINE_B</th>\n",
       "      <th>SLURRY_FLOW_LINE_C</th>\n",
       "      <th>WAFER_ROTATION</th>\n",
       "      <th>STAGE_ROTATION</th>\n",
       "      <th>HEAD_ROTATION</th>\n",
       "      <th>DRESSING_WATER_STATUS</th>\n",
       "      <th>EDGE_AIR_BAG_PRESSURE</th>\n",
       "      <th>AVG_REMOVAL_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.816371e+08</td>\n",
       "      <td>371447024</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9302.5</td>\n",
       "      <td>534.074074</td>\n",
       "      <td>292.592593</td>\n",
       "      <td>2666.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2790.75</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>565.6</td>\n",
       "      <td>34.651163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.909091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.816371e+08</td>\n",
       "      <td>371447024</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9302.5</td>\n",
       "      <td>534.074074</td>\n",
       "      <td>292.592593</td>\n",
       "      <td>2666.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2790.75</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>568.4</td>\n",
       "      <td>34.651163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.909091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.816371e+08</td>\n",
       "      <td>371447024</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9302.5</td>\n",
       "      <td>534.074074</td>\n",
       "      <td>292.592593</td>\n",
       "      <td>2666.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2790.75</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>568.4</td>\n",
       "      <td>34.651163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.909091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.816371e+08</td>\n",
       "      <td>371447024</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9302.5</td>\n",
       "      <td>534.074074</td>\n",
       "      <td>292.592593</td>\n",
       "      <td>2666.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2790.75</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>568.4</td>\n",
       "      <td>34.651163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.606061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.816371e+08</td>\n",
       "      <td>371447024</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9302.5</td>\n",
       "      <td>534.074074</td>\n",
       "      <td>292.592593</td>\n",
       "      <td>2666.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2790.75</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>571.2</td>\n",
       "      <td>34.651163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.909091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MACHINE_ID MACHINE_DATA     TIMESTAMP   WAFER_ID STAGE  CHAMBER  \\\n",
       "0          2            1  4.816371e+08  371447024     A      1.0   \n",
       "1          2            1  4.816371e+08  371447024     A      1.0   \n",
       "2          2            1  4.816371e+08  371447024     A      1.0   \n",
       "3          2            1  4.816371e+08  371447024     A      1.0   \n",
       "4          2            1  4.816371e+08  371447024     A      1.0   \n",
       "\n",
       "   USAGE_OF_BACKING_FILM  USAGE_OF_DRESSER  USAGE_OF_POLISHING_TABLE  \\\n",
       "0                 9302.5        534.074074                292.592593   \n",
       "1                 9302.5        534.074074                292.592593   \n",
       "2                 9302.5        534.074074                292.592593   \n",
       "3                 9302.5        534.074074                292.592593   \n",
       "4                 9302.5        534.074074                292.592593   \n",
       "\n",
       "   USAGE_OF_DRESSER_TABLE  ...  USAGE_OF_PRESSURIZED_SHEET  \\\n",
       "0                 2666.25  ...                     2790.75   \n",
       "1                 2666.25  ...                     2790.75   \n",
       "2                 2666.25  ...                     2790.75   \n",
       "3                 2666.25  ...                     2790.75   \n",
       "4                 2666.25  ...                     2790.75   \n",
       "\n",
       "   SLURRY_FLOW_LINE_A  SLURRY_FLOW_LINE_B  SLURRY_FLOW_LINE_C  WAFER_ROTATION  \\\n",
       "0            2.222222            0.909091               565.6       34.651163   \n",
       "1            2.222222            0.909091               568.4       34.651163   \n",
       "2            2.222222            0.909091               568.4       34.651163   \n",
       "3            2.222222            0.909091               568.4       34.651163   \n",
       "4            2.222222            0.909091               571.2       34.651163   \n",
       "\n",
       "   STAGE_ROTATION  HEAD_ROTATION  DRESSING_WATER_STATUS  \\\n",
       "0             0.0          156.8                    1.0   \n",
       "1             0.0          156.8                    1.0   \n",
       "2             0.0          156.8                    1.0   \n",
       "3             0.0          156.8                    1.0   \n",
       "4             0.0          156.8                    1.0   \n",
       "\n",
       "   EDGE_AIR_BAG_PRESSURE  AVG_REMOVAL_RATE  \n",
       "0              60.909091               NaN  \n",
       "1              60.909091               NaN  \n",
       "2              60.909091               NaN  \n",
       "3              60.606061               NaN  \n",
       "4              60.909091               NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wafer_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [WAFER_ID]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "wafer_extracted_data = pd.DataFrame()\n",
    "wafer_extracted_data['WAFER_ID'] = wafer\n",
    "\n",
    "print(wafer_extracted_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (2) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m feature_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([features_np])\n\u001b[0;32m     32\u001b[0m feature_df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWAFER_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, wafer)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mfeature_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTAGE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwafer_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTAGE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m feature_df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHAMBER\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39munique(wafer_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHAMBER\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     37\u001b[0m wafer_rows\u001b[38;5;241m.\u001b[39mappend(new_func(feature_df))\n",
      "File \u001b[1;32mc:\\Users\\Sadie\\anaconda3\\envs\\featureEngineeringMethods\\Lib\\site-packages\\pandas\\core\\frame.py:5158\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   5155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   5156\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 5158\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(loc, column, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[1;32mc:\\Users\\Sadie\\anaconda3\\envs\\featureEngineeringMethods\\Lib\\site-packages\\pandas\\core\\frame.py:5253\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5253\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5254\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5256\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sadie\\anaconda3\\envs\\featureEngineeringMethods\\Lib\\site-packages\\pandas\\core\\common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (2) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "# sourcery skip: dict-assign-update-to-union\n",
    "wafer_rows = []\n",
    "non_extracted_columns = [\"TIMESTAMP\", \"WAFER_ID\", \"CHAMBER\"]\n",
    "def new_func(feature_df):\n",
    "    return feature_df\n",
    "\n",
    "for wafer in unique_wafers:\n",
    "    wafer_data = training[training[\"WAFER_ID\"]==wafer]\n",
    "# Iterate through each numerical column and calculate the features using numpy\n",
    "    features_np = {}\n",
    "    for column in wafer_data.select_dtypes(include='number').columns:\n",
    "        if column in non_extracted_columns:\n",
    "            continue\n",
    "        col_data = wafer_data[column].values  # Convert the column to a numpy array\n",
    "        features_np.update({\n",
    "            f'{column}_Mean': np.mean(col_data),\n",
    "            f'{column}_Median': np.median(col_data),\n",
    "            f'{column}_StdDev': np.std(col_data, ddof=1),  # ddof=1 for sample standard deviation\n",
    "            f'{column}_Variance': np.var(col_data, ddof=1),  # ddof=1 for sample variance\n",
    "            f'{column}_Minimum': np.min(col_data),\n",
    "            f'{column}_Maximum': np.max(col_data),\n",
    "            f'{column}_Range': np.ptp(col_data),  # Peak-to-peak is a simpler way to compute range\n",
    "            f'{column}_Skewness': pd.Series(col_data).skew(),  # Using pandas for skew as numpy does not have a direct function\n",
    "            f'{column}_Kurtosis': pd.Series(col_data).kurt(),  # Using pandas for kurtosis as numpy does not have a direct function\n",
    "            f'{column}_25thPercentile': np.percentile(col_data, 25),\n",
    "            f'{column}_50thPercentile': np.percentile(col_data, 50),\n",
    "            f'{column}_75thPercentile': np.percentile(col_data, 75)\n",
    "        })\n",
    "    # Convert the features dictionary to a DataFrame\n",
    "    # Since we want all features in one row, we use pd.DataFrame and specify the index [0]\n",
    "    feature_df = pd.DataFrame([features_np])\n",
    "    feature_df.insert(0, \"WAFER_ID\", wafer)\n",
    "    \n",
    "    feature_df.insert(1, \"STAGE\", np.unique(wafer_data[\"STAGE\"]))\n",
    "    feature_df.insert(2, \"CHAMBER\", np.unique(wafer_data[\"CHAMBER\"])[0])\n",
    "\n",
    "    wafer_rows.append(new_func(feature_df))\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # # Convert the features dictionary to a DataFrame\n",
    "    # # Since we want all features in one row, we use pd.DataFrame and specify the index [0]\n",
    "    # feature_df = pd.DataFrame([features_np])\n",
    "    # feature_df.insert(0, \"WAFER_ID\", wafer)\n",
    "    # feature_df.insert(1, \"STAGE\", np.unique(wafer_data[\"STAGE\"]))\n",
    "    # feature_df.insert(2, \"CHAMBER\", np.unique(wafer_data[\"CHAMBER\"])[0])\n",
    "\n",
    "    # wafer_rows.append(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Sadie\\anaconda3\\envs\\featureEngineeringMethods\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfeature_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sadie\\anaconda3\\envs\\featureEngineeringMethods\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Sadie\\anaconda3\\envs\\featureEngineeringMethods\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "feature_df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['STAGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6., nan])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['CHAMBER'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featureEngineeringMethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
